left_join(ratings, by=c("st_cd_fips" = "geoid", "year" = "year")) %>%
left_join(polls, by="year")
# Select variables for pooled model
pooled_df = model_df %>%
select(DemVotes, RepVotes, code, DemIncumbent, RepIncumbent, DemPresident, IsMidterm) %>%
drop_na()
# Select variables for unpooled models
unpooled_df = model_df %>%
select(DemVotes, RepVotes, DemPctPrev, DemPolls, st_cd_fips) %>%
drop_na()
# The pooled model
pooled_mod = glm(cbind(DemVotes, RepVotes) ~ code + DemIncumbent + RepIncumbent + DemPresident + IsMidterm,
family=binomial, data=pooled_df)
# The unpooled models - one for each district
ids = c()
unpooled_mods = list()
i = 0
for (id in unique(unpooled_df$st_cd_fips)) {
i = i + 1
df = filter(unpooled_df, st_cd_fips == id)
ids[i] = id
unpooled_mods[[i]] = glm(cbind(DemVotes, RepVotes) ~ DemPctPrev + DemPolls, family=binomial, data=unpooled_df)
}
# A function that makes a prediction on a row of data
predict_entry = function(row) {
ind = which(ids == row$st_cd_fips)
if (length(ind == 1)) {
unpooled_mod = unpooled_mods[[ind]]
pooled_pred = predict(pooled_mod, row, "response")
unpooled_pred = predict(unpooled_mod, row, "response")
return(0.5 * pooled_pred + 0.5 * unpooled_pred)
}
}
# Make the predictions
model_df$Predicted = NA
for (i in 1:nrow(model_df)) {
model_df$Predicted[i] = predict_entry(model_df[i, ])
}
model_df$Predicted
i
# Put all the data together
model_df = votes %>%
left_join(ratings, by=c("st_cd_fips" = "geoid", "year" = "year")) %>%
left_join(polls, by="year")
# Select variables for pooled model
pooled_df = model_df %>%
select(DemVotes, RepVotes, code, DemIncumbent, RepIncumbent, DemPresident, IsMidterm) %>%
drop_na()
# Select variables for unpooled models
unpooled_df = model_df %>%
select(DemVotes, RepVotes, DemPctPrev, DemPolls, st_cd_fips) %>%
drop_na()
# The pooled model
pooled_mod = glm(cbind(DemVotes, RepVotes) ~ code + DemIncumbent + RepIncumbent + DemPresident + IsMidterm,
family=binomial, data=pooled_df)
# The unpooled models - one for each district
ids = c()
unpooled_mods = list()
i = 0
for (id in unique(unpooled_df$st_cd_fips)) {
i = i + 1
df = filter(unpooled_df, st_cd_fips == id)
ids[i] = id
unpooled_mods[[i]] = glm(cbind(DemVotes, RepVotes) ~ DemPctPrev + DemPolls, family=binomial, data=unpooled_df)
}
# A function that makes a prediction on a row of data
predict_entry = function(row) {
ind = which(ids == row$st_cd_fips)
if (length(ind == 1)) {
unpooled_mod = unpooled_mods[[ind]]
pooled_pred = predict(pooled_mod, row, "response")
unpooled_pred = predict(unpooled_mod, row, "response")
return(0.5 * pooled_pred + 0.5 * unpooled_pred)
} else {
return(NA)
}
}
# Make the predictions
model_df$Predicted = NA
for (i in 1:nrow(model_df)) {
model_df$Predicted[i] = predict_entry(model_df[i, ])
}
# Scatter predicted vs. actual
model_df %>% ggplot(aes(Predicted, DemPct)) +
geom_point()
model_df$Predicted
is.na(model_df$Predicted)
is.na(model_df$Predicted) %>% sum()
# Scatter predicted vs. actual
model_df %>% ggplot(aes(Predicted, DemPct)) +
geom_point()
# Scatter predicted vs. actual
model_df %>% ggplot(aes(Predicted, DemPct)) +
geom_point() +
geom_abline(slope=1)
# Scatter predicted vs. actual
model_df %>% ggplot(aes(Predicted*100, DemPct)) +
geom_point() +
geom_abline(slope=1)
# Scatter predicted vs. actual
model_df %>% ggplot(aes(DemPct, Predicted*100)) +
geom_point() +
geom_abline(slope=1) +
ylab("Predicted Vote Share For Democrat Candidate") +
xlab("Actual Vote Share For Democrat Candidate")
# Scatter predicted vs. actual
model_df %>% ggplot(aes(Predicted*100, DemPct)) +
geom_point() +
geom_abline(slope=1) +
xlab("Predicted Vote Share For Democrat Candidate") +
ylab("Actual Vote Share For Democrat Candidate")
# Scatter predicted vs. actual
model_df %>% ggplot(aes(Predicted*100, DemPct)) +
geom_point() +
geom_hline(yintercept=50) +
geom_vline(xintercept=50)
xlab("Predicted Probability For Democrat Candidate") +
ylab("Actual Vote Share For Democrat Candidate")
# Scatter predicted vs. actual
model_df %>% ggplot(aes(Predicted*100, DemPct)) +
geom_point() +
geom_hline(yintercept=50) +
geom_vline(xintercept=50) +
xlab("Predicted Probability For Democrat Candidate") +
ylab("Actual Vote Share For Democrat Candidate")
# Set R Markdown settings and load necessary packages
knitr::opts_chunk$set(echo=FALSE, fig.align="center")
knitr::opts_knit$set(root.dir="~/Desktop/GOV1347.nosync")
library(tidyverse)
library(gridExtra)
library(usmap)
library(sf)
library(rmapshaper)
library(lubridate)
# load geographic data
get_congress_map = function() {
tmp_file = tempfile()
tmp_dir = tempdir()
download.file("https://cdmaps.polisci.ucla.edu/shp/districts114.zip", tmp_file)
unzip(zipfile=tmp_file, exdir=tmp_dir)
fpath = paste(tmp_dir, "districtShapes/districts114.shp", sep="/")
st_read(fpath)
}
# Get the district map
districts = get_congress_map()
districts$DISTRICT = as.numeric(districts$DISTRICT)
# Read in the voting data, filter for elections where there was a Democrat and a
# Republican, and join with relevant variables from the previous election
votes = read_csv("data/incumb_dist_1948-2020.csv") %>%
filter(!is.na(RepCandidate) & !is.na(DemCandidate)) %>%
rename(DemPct = DemVotesMajorPercent) %>%
mutate(DemPresident = year %in% c(1978, 1980, 1994, 1996, 1998, 2000, 2010, 2012, 2014, 2016),
IsMidterm = year %% 4 == 2)
votes = votes %>%
left_join((
votes %>%
mutate(year = year + 2) %>%
select(year, st_cd_fips, DemPct) %>%
rename(DemPctPrev = DemPct)
), c("year", "st_cd_fips"))
# Get the Inside Elections ratings and create logical columns for the status of the incumbent
ratings = read_csv("data/inside_elections.csv") %>%
mutate(DemIncumbent = inc_party == "Democrat",
RepIncumbent = inc_party == "Republican")
# Read in the state unemployment data, filtering for the Q4 numbers
unemp_Q4 = read_csv("data/unemployment_state_monthly.csv") %>%
filter(Month == 10) %>%
rename(UnempQ4 = Unemployed_prct) %>%
select(Year, `State and area`, UnempQ4)
# Read in the state unemployment data, filtering for the Q3 numbers
unemp_Q3 = read_csv("data/unemployment_state_monthly.csv") %>%
filter(Month == 7) %>%
rename(UnempQ3 = Unemployed_prct) %>%
select(Year, `State and area`, UnempQ3)
# Get the poll data, filter for polls within 1 month of the election, and take simple average of results
polls = read_csv("data/polls_df.csv") %>%
filter(emonth %in% c(10, 11)) %>%
mutate(isDemocrat = party == "D") %>%
group_by(year) %>%
summarize(D = sum(support * isDemocrat) / sum(isDemocrat), R = sum(support * (1 - isDemocrat)) / sum(1 - isDemocrat)) %>%
mutate(DemPolls = D / (D + R))
autocorrs = c()
ids = c()
# For each district, calculate the autocorrelation
# Only if we have enough observations to be confident in the estimate
for (id in unique(votes$st_cd_fips)) {
df = votes %>%
filter(st_cd_fips == id) %>%
select(DemPct, DemPctPrev)
if (nrow(df) > 16) {
df = drop_na(df)
autocorrs = c(cor(df$DemPct, df$DemPctPrev), autocorrs)
ids = c(id, ids)
}
}
# Create a dataframe with the results
df1 = data.frame(st_cd_fips = ids, Autocorrelation = autocorrs)
# Make the histogram
df1 %>% ggplot(aes(Autocorrelation)) +
geom_histogram(bins=40) +
ggtitle("Histogram of District-Specific Vote Share Autocorrelations") +
xlab("Autocorrelation of Democrat Vote Share") +
ylab("Number of Districts")
# Join the district data to our data using FIPS code
fips = select(read_csv("data/incumb_dist_1948-2020.csv"), st_cd_fips, state, district_num) %>% unique()
fips$district_num = as.numeric(fips$district_num)
districts = left_join(districts, fips, c("STATENAME" = "state", "DISTRICT" = "district_num"))
# Simplify the boundaries so it can plot
districts_simp <- ms_simplify(inner_join(districts, df1, "st_cd_fips"), keep = 0.01)
# Make the map
ggplot() +
geom_sf(data=districts_simp, aes(fill=Autocorrelation),
inherit.aes=FALSE, alpha=0.9) +
scale_fill_gradient(low="white", high="blue", limits=c(0.5, 1)) +
coord_sf(xlim=c(-124.8, -66.9), ylim=c(24.5, 49.4), expand=FALSE) +
theme_void() +
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
axis.title.y=element_blank(),
axis.text.y=element_blank(),
axis.ticks.y=element_blank()) +
ggtitle("Autocorrelation of Democrat Vote Share, By District")
unemps = c()
ids = c()
ts = c()
# For each district, calculate the regression coefficients and t-statistics
# Only if we have enough observations to be confident in the estimate
for (id in unique(votes$st_cd_fips)) {
df = votes %>%
filter(st_cd_fips == id) %>%
inner_join(unemp_Q4, by=c("year" = "Year", "state" = "State and area")) %>%
inner_join(unemp_Q3, by=c("year" = "Year", "state" = "State and area")) %>%
select(DemPct, UnempQ4, UnempQ3, DemPctPrev) %>%
mutate(PctChange = (UnempQ4 - UnempQ3) / UnempQ3)
if (nrow(df) > 16) {
mod = lm(DemPct ~ UnempQ4 + DemPctPrev, data=drop_na(df))
ts = c(summary(mod)$coefficients["UnempQ4", "t value"], ts)
unemps = c(mod$coefficients["UnempQ4"], unemps)
ids = c(id, ids)
}
}
# Put the data into a dataframe
df2 = data.frame(st_cd_fips = ids, Coefficients = unemps, TStatistics = ts)
# Make the histogram of coefficients
p1 = df2 %>% ggplot(aes(Coefficients)) +
geom_histogram(bins=40) +
ggtitle("Histogram of District-Specific Unemployment Coefficients") +
xlab("Coefficient of Statewide Q8 Unemployment Rate,\nin Model for Democrat Vote Share") +
ylab("Number of Districts")
# Make the histogram of t-statistics
p2 = df2 %>% ggplot(aes(TStatistics)) +
geom_histogram(bins=40) +
ggtitle("Histogram of District-Specific Unemployment Coefficient t-Statistics") +
xlab("t-Statistic of Coefficient of Statewide Q8 Unemployment Rate,\nin Model for Democrat Vote Share") +
ylab("Number of Districts")
grid.arrange(p1, p2, nrow=2)
# Put all the data together
model_df = votes %>%
left_join(ratings, by=c("st_cd_fips" = "geoid", "year" = "year")) %>%
left_join(polls, by="year")
# A function that trains the two models, returning a prediction function
train_models = function(df) {
# Select variables for pooled model
pooled_df = df %>%
select(DemVotes, RepVotes, code, DemIncumbent, RepIncumbent, DemPresident, IsMidterm) %>%
drop_na()
# Select variables for unpooled models
unpooled_df = df %>%
select(DemVotes, RepVotes, DemPctPrev, DemPolls, st_cd_fips) %>%
drop_na()
# The pooled model
pooled_mod = glm(cbind(DemVotes, RepVotes) ~ code + DemIncumbent + RepIncumbent + DemPresident + IsMidterm,
family=binomial, data=pooled_df)
# The unpooled models - one for each district
ids = c()
unpooled_mods = list()
i = 0
for (id in unique(unpooled_df$st_cd_fips)) {
i = i + 1
df = filter(unpooled_df, st_cd_fips == id)
ids[i] = id
unpooled_mods[[i]] = glm(cbind(DemVotes, RepVotes) ~ DemPctPrev + DemPolls, family=binomial, data=unpooled_df)
}
# A function that makes a prediction on a row of data
predict_entry = function(row) {
ind = which(ids == row$st_cd_fips)
if (length(ind == 1)) {
unpooled_mod = unpooled_mods[[ind]]
pooled_pred = predict(pooled_mod, row, "response")
unpooled_pred = predict(unpooled_mod, row, "response")
return(0.5 * pooled_pred + 0.5 * unpooled_pred)
} else {
return(NA)
}
}
# Return the prediction function
return(predict_entry)
}
full_prediction = train_models(model_df)
# Make the predictions
model_df$Predicted = NA
for (i in 1:nrow(model_df)) {
model_df$Predicted[i] = full_prediction(model_df[i, ])
}
# Scatter predicted vs. actual
model_df %>% ggplot(aes(Predicted*100, DemPct)) +
geom_point() +
geom_hline(yintercept=50) +
geom_vline(xintercept=50) +
xlab("Predicted Probability For Democrat Candidate") +
ylab("Actual Vote Share For Democrat Candidate")
!TRUE
# Replicate the same procedure with in sample/out of sample splits
misclass = replicate(10, {
# Get in sample and out of sample data
in_sample_inds = sample.int(n=nrow(model_df), size=floor(0.75*nrow(model_df)), replace=FALSE)
df_in = model_df[in_sample_inds, ]
df_out = model_df[-in_sample_inds, ]
# Fit the prediction to the in sample data
boot_prediction = train_models(df_in)
# Make the predictions on the out of sample data
df_out$Predicted = NA
for (i in 1:nrow(df_out)) {
df_out$Predicted[i] = boot_prediction(df_out[i, ])
}
# Calculate misclassification rate
df_out$DemWin = df_out$DemPct > 50
df_out$PredWin = df_out$Predicted > 0.5
sum(df_out$DemWin & !df_out$PredWin) + sum(!df_out$DemWin & df_out$PredWin)
})
mean(misclass)
misclass
df_out
?sum
# Replicate the same procedure with in sample/out of sample splits
misclass = replicate(10, {
# Get in sample and out of sample data
in_sample_inds = sample.int(n=nrow(model_df), size=floor(0.75*nrow(model_df)), replace=FALSE)
df_in = model_df[in_sample_inds, ]
df_out = model_df[-in_sample_inds, ]
# Fit the prediction to the in sample data
boot_prediction = train_models(df_in)
# Make the predictions on the out of sample data
df_out$Predicted = NA
for (i in 1:nrow(df_out)) {
df_out$Predicted[i] = boot_prediction(df_out[i, ])
}
# Calculate misclassification rate
df_out$DemWin = df_out$DemPct > 50
df_out$PredWin = df_out$Predicted > 0.5
df_out$Misclassified = (df_out$DemWin & !df_out$PredWin) | (!df_out$DemWin & df_out$PredWin)
mean(df_out$Misclassified, na.rm=TRUE)
})
# Replicate the same procedure with in sample/out of sample splits
misclass = replicate(10, {
# Get in sample and out of sample data
in_sample_inds = sample.int(n=nrow(model_df), size=floor(0.75*nrow(model_df)), replace=FALSE)
df_in = model_df[in_sample_inds, ]
df_out = model_df[-in_sample_inds, ]
# Fit the prediction to the in sample data
boot_prediction = train_models(df_in)
# Make the predictions on the out of sample data
df_out$Predicted = NA
for (i in 1:nrow(df_out)) {
df_out$Predicted[i] = boot_prediction(df_out[i, ])
}
# Calculate misclassification rate
df_out$DemWin = df_out$DemPct > 50
df_out$PredWin = df_out$Predicted > 0.5
df_out$Misclassified = (df_out$DemWin & !df_out$PredWin) | (!df_out$DemWin & df_out$PredWin)
mean(df_out$Misclassified, na.rm=TRUE)
})
mean(misclass)
# Get the data for today
today = read_csv("data/inside_elections.csv") %>%
filter(year == 2022) %>%
left_join((
votes %>%
filter(year == 2020) %>%
select(DemPct, st_cd_fips, district_num, state) %>%
rename(DemPctPrev = DemPct, State = state)
), c("geoid" = "st_cd_fips")) %>%
mutate(DemIncumbent = inc_party == "Democrat",
RepIncumbent = inc_party == "Democrat",
IsMidterm = TRUE,
DemPresident = TRUE,
DemPolls = 0.503)
# Calculate the predictions for today
today$DemProbability = NA
for (i in 1:nrow(today)) {
today$DemProbability[i] = full_prediction(today[i, ])
if (is.na(today$DemProbability[i])) {
today$DemProbability[i] = ifelse(is.na(today$DemIncumbent[i]), 0.5, as.numeric(today$DemIncumbent[i]))
}
}
seat_share = sum(today$DemProbability)
seat_share
225 / 435
seat_share = sum(today$DemProbability > 0.5)
seat_share
today$DemProbability
today
view(today)
# Get the data for today
today = read_csv("data/inside_elections.csv") %>%
filter(year == 2022) %>%
left_join((
votes %>%
filter(year == 2020) %>%
select(DemPct, st_cd_fips, district_num, state) %>%
rename(DemPctPrev = DemPct, State = state)
), c("geoid" = "st_cd_fips")) %>%
mutate(DemIncumbent = inc_party == "Democrat",
RepIncumbent = inc_party == "Democrat",
IsMidterm = TRUE,
DemPresident = TRUE,
DemPolls = 0.503) %>%
rename(st_cd_fips = geoid)
# Calculate the predictions for today
today$DemProbability = NA
for (i in 1:nrow(today)) {
today$DemProbability[i] = full_prediction(today[i, ])
if (is.na(today$DemProbability[i])) {
today$DemProbability[i] = ifelse(is.na(today$DemIncumbent[i]), 0.5, as.numeric(today$DemIncumbent[i]))
}
}
seat_share = sum(today$DemProbability)
seat_share
seat_share = sum(today$DemProbability > 0.5)
seat_share
today$DemProbability
seat_share
seat_share = sum(today$DemProbability > 0.5)
seat_share = sum(today$DemProbability)
seat_share
223 / 435
# Simulate the election 10000 times
seats = replicate(10000, {
probs = today$DemProbability
races = rbernoulli(length(probs), probs)
sum(races)
})
# Make a histogram of the results
ggplot(aes(DemSeats), data=data.frame("DemSeats" = seats)) +
geom_histogram(aes(y = ..density..), binwidth=4) +
xlab("Seats Won By Democrats") +
ylab("Density") +
stat_function(fun = function(x) dnorm(x, 0, summary(model1)$sigma)) +
geom_vline(xintercept=218, color="blue") +
ggtitle("Histogram of Simulated 2022 Elections")
# Simulate the election 10000 times
seats = replicate(10000, {
probs = today$DemProbability
races = rbernoulli(length(probs), probs)
sum(races)
})
# Make a histogram of the results
ggplot(aes(DemSeats), data=data.frame("DemSeats" = seats)) +
geom_histogram(aes(y = ..density..), binwidth=4) +
xlab("Seats Won By Democrats") +
ylab("Density") +
geom_vline(xintercept=218, color="blue") +
ggtitle("Histogram of Simulated 2022 Elections")
# Simulate the election 10000 times
seats = replicate(10000, {
probs = today$DemProbability
races = rbernoulli(length(probs), probs)
sum(races)
})
# Make a histogram of the results
ggplot(aes(DemSeats), data=data.frame("DemSeats" = seats)) +
geom_histogram(binwidth=4) +
xlab("Seats Won By Democrats") +
ylab("Number of Elections") +
geom_vline(xintercept=218, color="blue") +
ggtitle("Histogram of Simulated 2022 Elections")
# Simulate the election 10000 times
seats = replicate(10000, {
probs = today$DemProbability
races = rbernoulli(length(probs), probs)
sum(races)
})
# Make a histogram of the results
ggplot(aes(DemSeats), data=data.frame("DemSeats" = seats)) +
geom_histogram(binwidth=4) +
xlab("Seats Won By Democrats") +
ylab("Number of Simulated Elections") +
geom_vline(xintercept=218, color="blue") +
ggtitle("Histogram of Simulated 2022 Elections")
# Simplify the boundaries so it can plot
districts_simp = ms_simplify(inner_join(districts, today, c("st_cd_fips" = "geoid")), keep = 0.01)
# Simplify the boundaries so it can plot
districts_simp = ms_simplify(inner_join(districts, today, "st_cd_fips"), keep = 0.01)
# Make the map
ggplot() +
geom_sf(data=districts_simp, aes(fill=DemProbability),
inherit.aes=FALSE, alpha=0.9) +
scale_fill_gradient(low="white", high="blue", limits=c(0.25, 0.75)) +
coord_sf(xlim=c(-124.8, -66.9), ylim=c(24.5, 49.4), expand=FALSE) +
theme_void() +
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
axis.title.y=element_blank(),
axis.text.y=element_blank(),
axis.ticks.y=element_blank()) +
ggtitle("Probability of Democrat Candidate Winning, By District")
today$DemProbability
today$DemProbability %>% min()
today$DemProbability %>% arrange()
today$DemProbability %>% sort()
