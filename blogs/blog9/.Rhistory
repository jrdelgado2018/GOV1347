cook = read_csv("data/cook.csv")
# Put all the data together
df2 = votes_ideo %>%
left_join(demo, c("year", "st_cd_fips")) %>%
left_join(inside_elections, c("year" = "year", "st_cd_fips" = "geoid"))%>%
left_join(cook, c("year" = "year", "st_cd_fips" = "geoid")) %>%
mutate(Experts = 0.5 * code.x + 0.5 * code.y,
MidtermFlag = IsMidterm * DemPresident - IsMidterm * (1 - DemPresident))
# A function that trains the pooled model, returning it
train_pooled_model = function(df) {
# Select variables for the pooled model
pooled_df = df %>%
select(DemVotes, RepVotes, Experts, `20_29`, female,
black_or_latino, nominate_dim1, Incumbent, MidtermFlag) %>%
drop_na()
# The pooled model
pooled_mod = glm(cbind(DemVotes, RepVotes) ~ Experts + `20_29` + female + black_or_latino + nominate_dim1 + Incumbent + MidtermFlag,
family=binomial, data=pooled_df)
return(pooled_mod)
}
districts_mod = train_pooled_model(df2)
summary(districts_mod)
# A function that gets the unpooled prediction and standard error for a dataframe, assumed to only contain one year
unpooled_prediction = function(mods, df) {
df_use = df %>%
select(state, DemVotes, RepVotes, Interaction,
UnempQ4, DemPolls, DemPctPrev, MidtermFlag) %>%
right_join(pops, "state")
df_use$Pred = NA
df_use$SE = NA
for (i in 1:nrow(df_use)) {
row = df_use[i, ]
pred = predict(mods[[row$state]], row, se.fit=TRUE, type="response")
df_use[i, "Pred"] = pred$fit
df_use[i, "SE"] = pred$se.fit
}
unused_states = 1 - sum(filter(df_use, is.na(Pred))$prop)
return(c(
sum(df_use$Pred * df_use$prop / unused_states, na.rm=TRUE),
sum(df_use$SE * df_use$prop / unused_states, na.rm=TRUE)
))
}
# A function that gets the pooled prediction and standard error for a dataframe, assumed to only contain one year
pooled_prediction = function(mod, df) {
df_use = df %>%
select(DemVotes, RepVotes, Experts, `20_29`, female,
black_or_latino, nominate_dim1, Incumbent, MidtermFlag)
df_use$Pred = NA
df_use$SE = NA
for (i in 1:nrow(df_use)) {
row = df_use[i, ]
pred = predict(mod, row, se.fit=TRUE, type="response")
df_use[i, "Pred"] = pred$fit
df_use[i, "SE"] = pred$se.fit
}
num_districts = sum(!is.na(df_use$Pred))
return(c(
sum(df_use$Pred / num_districts, na.rm=TRUE),
sum(df_use$SE / num_districts, na.rm=TRUE)
))
}
# A function that fits the alphas, returning a final prediction model
final_prediction = function(df1, df2) {
# Get the models
unpooled_mods = train_unpooled_models(df1)
pooled_mod = train_pooled_model(df2)
# Get the individual predictions for each year
actuals = c()
pooled_preds = c()
unpooled_preds = c()
i = 1
for (yr in unique(df2$year)) {
actuals[i] = filter(actual, year==yr)$ActualPct
pooled_preds[i] = pooled_prediction(pooled_mod, filter(df2, year==yr))[1]
unpooled_preds[i] = unpooled_prediction(unpooled_mods, filter(df1, year==yr))[1]
i = i + 1
}
df = data.frame(actual = actuals, pooled = pooled_preds, unpooled = unpooled_preds)
ensemble = lm(actual ~ pooled + unpooled, data=df)
return(ensemble)
}
ensemble = final_prediction(df1, df2)
df_plot1 = ensemble$model
df_plot1$predicted = predict(ensemble, df_plot1)
df_plot1 %>% ggplot(aes(100*predicted, 100*actual)) +
geom_point() +
geom_abline(slope=1, intercept=0) +
ylab("Actual Nationwide Democrat Vote Share (%)") +
xlab("Predicted Nationwide Democrat Vote Share (%)")
# Get the state-level data for today
today1 = votes %>%
filter(year == 2020) %>%
select(state, DemPct) %>%
rename(DemPctPrev = DemPct) %>%
left_join(read_csv("data/unemp2022.csv"), "state") %>%
mutate(Interaction = UnempQ4,
MidtermFlag = 1,
DemPolls = 0.503,
Predicted = NA)
# Get the predictions for each state
for (i in 1:nrow(today1)) {
row = today1[i, ]
today1$Predicted[i] = predict(all_state_mods[[row$state]], row, type="response")
}
# Get the district-level data for today
today2 = filter(inside_elections, year == 2022) %>%
left_join(filter(cook, year == 2022), "geoid") %>%
left_join(demo %>%
filter(year == 2020 | year == 2018) %>%
group_by(st_cd_fips) %>%
summarize(`20_29` = mean(`20_29`),
female = mean(female),
black_or_latino = mean(black_or_latino)),
c("geoid" = "st_cd_fips")) %>%
left_join(read_csv("data/HSall_members.csv"),
c("geoid" = "st_cd_fips")) %>%
mutate(MidtermFlag = 1,
Experts = 0.5 * code.x + 0.5 * code.y,
Predicted = NA)
# Get the predictions for each district
for (i in 1:nrow(today2)) {
row = today2[i, ]
today2$Predicted[i] = predict(districts_mod, row, type="response")
}
states = us_map()
plot_usmap(data=today1, regions="states", values="Predicted") +
theme_void() +
scale_fill_gradient(low="white", high="blue", name="% of Votes") +
ggtitle("Predicted Vote Share Achieved by Democrats, 2022 Midterm Election")
# Join the district data to our data using FIPS code
#fips = select(read_csv("data/incumb_dist_1948-2020.csv"), st_cd_fips, state, district_num) %>% unique()
#fips$district_num = as.numeric(fips$district_num)
#districts = left_join(districts, fips, c("STATENAME" = "state", "DISTRICT" = "district_num"))
# Simplify the boundaries so it can plot
districts_simp = ms_simplify(inner_join(districts, today2, c("st_cd_fips" = "geoid")), keep = 0.01)
# Join the district data to our data using FIPS code
fips = select(read_csv("data/incumb_dist_1948-2020.csv"), st_cd_fips, state, district_num) %>% unique()
fips$district_num = as.numeric(fips$district_num)
districts = left_join(districts, fips, c("STATENAME" = "state", "DISTRICT" = "district_num"))
# Simplify the boundaries so it can plot
districts_simp = ms_simplify(inner_join(districts, today2, c("st_cd_fips" = "geoid")), keep = 0.01)
# Make the map
ggplot() +
geom_sf(data=districts_simp, aes(fill=Predicted),
inherit.aes=FALSE, alpha=0.9) +
scale_fill_gradient(low="white", high="blue") +
coord_sf(xlim=c(-124.8, -66.9), ylim=c(24.5, 49.4), expand=FALSE) +
theme_void() +
theme(axis.title.x=element_blank(),
axis.text.x=element_blank(),
axis.ticks.x=element_blank(),
axis.title.y=element_blank(),
axis.text.y=element_blank(),
axis.ticks.y=element_blank()) +
ggtitle("Predicted Vote Share Achieved by Democrats, 2022 Midterm Election")
unpooled_pred = unpooled_prediction(all_state_mods, today1)
# A function that gets the unpooled prediction and standard error for a dataframe, assumed to only contain one year
unpooled_prediction = function(mods, df) {
df_use = df %>%
select(state, Interaction, UnempQ4, DemPolls, DemPctPrev, MidtermFlag) %>%
right_join(pops, "state")
df_use$Pred = NA
df_use$SE = NA
for (i in 1:nrow(df_use)) {
row = df_use[i, ]
pred = predict(mods[[row$state]], row, se.fit=TRUE, type="response")
df_use[i, "Pred"] = pred$fit
df_use[i, "SE"] = pred$se.fit
}
unused_states = 1 - sum(filter(df_use, is.na(Pred))$prop)
return(c(
sum(df_use$Pred * df_use$prop / unused_states, na.rm=TRUE),
sum(df_use$SE * df_use$prop / unused_states, na.rm=TRUE)
))
}
# A function that gets the pooled prediction and standard error for a dataframe, assumed to only contain one year
pooled_prediction = function(mod, df) {
df_use = df %>%
select(Experts, `20_29`, female, black_or_latino, nominate_dim1, Incumbent, MidtermFlag)
df_use$Pred = NA
df_use$SE = NA
for (i in 1:nrow(df_use)) {
row = df_use[i, ]
pred = predict(mod, row, se.fit=TRUE, type="response")
df_use[i, "Pred"] = pred$fit
df_use[i, "SE"] = pred$se.fit
}
num_districts = sum(!is.na(df_use$Pred))
return(c(
sum(df_use$Pred / num_districts, na.rm=TRUE),
sum(df_use$SE / num_districts, na.rm=TRUE)
))
}
# A function that fits the alphas, returning a final prediction model
final_prediction = function(df1, df2) {
# Get the models
unpooled_mods = train_unpooled_models(df1)
pooled_mod = train_pooled_model(df2)
# Get the individual predictions for each year
actuals = c()
pooled_preds = c()
unpooled_preds = c()
i = 1
for (yr in unique(df2$year)) {
actuals[i] = filter(actual, year==yr)$ActualPct
pooled_preds[i] = pooled_prediction(pooled_mod, filter(df2, year==yr))[1]
unpooled_preds[i] = unpooled_prediction(unpooled_mods, filter(df1, year==yr))[1]
i = i + 1
}
df = data.frame(actual = actuals, pooled = pooled_preds, unpooled = unpooled_preds)
ensemble = lm(actual ~ pooled + unpooled, data=df)
return(ensemble)
}
ensemble = final_prediction(df1, df2)
unpooled_pred = unpooled_prediction(all_state_mods, today1)
pooled_pred = pooled_prediction(districts_mod, today2)
pooled_pred
unpooled_pred
unpooled_pred = unpooled_prediction(all_state_mods, today1)
pooled_pred = pooled_prediction(districts_mod, today2)
df_final = data.frame(pooled = c(pooled_pred[0], pooled_pred[0] - 2 * pooled_pred[1], pooled_pred[0] + 2 * pooled_pred[1]),
unpooled = c(unpooled_pred[0], unpooled_pred[0] - 2 * unpooled_pred[1], unpooled_pred[0] + 2 * unpooled_pred[1]))
df_final
c(pooled_pred[0], pooled_pred[0] - 2 * pooled_pred[1], pooled_pred[0] + 2 * pooled_pred[1])
unpooled_pred = unpooled_prediction(all_state_mods, today1)
pooled_pred = pooled_prediction(districts_mod, today2)
df_final = data.frame(pooled = c(pooled_pred[1], pooled_pred[1] - 2 * pooled_pred[2], pooled_pred[1] + 2 * pooled_pred[2]),
unpooled = c(unpooled_pred[1], unpooled_pred[1] - 2 * unpooled_pred[2], unpooled_pred[1] + 2 * unpooled_pred[2]))
df_final
unpooled_pred = unpooled_prediction(all_state_mods, today1)
pooled_pred = pooled_prediction(districts_mod, today2)
df_final = data.frame(pooled = c(pooled_pred[1], pooled_pred[1] - 2 * pooled_pred[2], pooled_pred[1] + 2 * pooled_pred[2]),
unpooled = c(unpooled_pred[1], unpooled_pred[1] - 2 * unpooled_pred[2], unpooled_pred[1] + 2 * unpooled_pred[2]))
df_final$predicted = predict(ensemble, df_final, interval="prediction")$fit
predict(ensemble, df_final, interval="prediction")
unpooled_pred = unpooled_prediction(all_state_mods, today1)
pooled_pred = pooled_prediction(districts_mod, today2)
df_final = data.frame(pooled = c(pooled_pred[1],
pooled_pred[1] - 2 * pooled_pred[2],
pooled_pred[1] - 2 * pooled_pred[2],
pooled_pred[1] + 2 * pooled_pred[2],
pooled_pred[1] + 2 * pooled_pred[2]),
unpooled = c(unpooled_pred[1],
unpooled_pred[1] - 2 * unpooled_pred[2],
unpooled_pred[1] + 2 * unpooled_pred[2],
unpooled_pred[1] - 2 * unpooled_pred[2],
unpooled_pred[1] + 2 * unpooled_pred[2]))
df_final$fit = data.frame(predict(ensemble, df_final))$fit
df_final
unpooled_pred = unpooled_prediction(all_state_mods, today1)
pooled_pred = pooled_prediction(districts_mod, today2)
df_final = data.frame(pooled = c(pooled_pred[1],
pooled_pred[1] - 2 * pooled_pred[2],
pooled_pred[1] - 2 * pooled_pred[2],
pooled_pred[1] + 2 * pooled_pred[2],
pooled_pred[1] + 2 * pooled_pred[2]),
unpooled = c(unpooled_pred[1],
unpooled_pred[1] - 2 * unpooled_pred[2],
unpooled_pred[1] + 2 * unpooled_pred[2],
unpooled_pred[1] - 2 * unpooled_pred[2],
unpooled_pred[1] + 2 * unpooled_pred[2]))
df_final$fit = predict(ensemble, df_final)
df_final
unpooled_pred = unpooled_prediction(all_state_mods, today1)
pooled_pred = pooled_prediction(districts_mod, today2)
final_prediction = ensemble$coefficients[["(intercept)"]] +
ensemble$coefficients[["pooled"]] * pooled_pred[1] +
ensemble$coefficients[["unpooled"]] * unpooled_pred[1]
unpooled_pred = unpooled_prediction(all_state_mods, today1)
pooled_pred = pooled_prediction(districts_mod, today2)
final_prediction = ensemble$coefficients[["(Intercept)"]] +
ensemble$coefficients[["pooled"]] * pooled_pred[1] +
ensemble$coefficients[["unpooled"]] * unpooled_pred[1]
final_se = abs(ensemble$coefficients[["pooled"]]) * pooled_pred[2] +
abs(ensemble$coefficients[["unpooled"]]) * unpooled_pred[2]
final_prediction
final_se
0.4918384 - 2 * 0.0001441363
unpooled_pred
pooled_pred
(0.4846319294 - 2 * 0.0002179566) * -0.3 + 0.9 + 1.1 * (4.954185e-01 + 2 * 7.186313e-05)
(0.4846319294 - 2 * 0.0002179566) * -0.3 + 0.09 + 1.1 * (4.954185e-01 + 2 * 7.186313e-05)
(0.4846319294 + 2 * 0.0002179566) * -0.3 + 0.09 + 1.1 * (4.954185e-01 - 2 * 7.186313e-05)
(0.4846319294 + 0 * 0.0002179566) * -0.3 + 0.09 + 1.1 * (4.954185e-01 - 0 * 7.186313e-05)
summary(ensemble)
summary(ensemble)$se
summary(ensemble)$coefficients
summary(ensemble)$coefficients["(Intercept)", "Std. Error"]
unpooled_pred = unpooled_prediction(all_state_mods, today1)
pooled_pred = pooled_prediction(districts_mod, today2)
final_prediction = ensemble$coefficients[["(Intercept)"]] +
ensemble$coefficients[["pooled"]] * pooled_pred[1] +
ensemble$coefficients[["unpooled"]] * unpooled_pred[1]
final_se = abs(ensemble$coefficients[["pooled"]]) * pooled_pred[2] +
summary(ensemble)$coefficients["pooled", "Std. Error"] * pooled_pred[1] +
summary(ensemble)$coefficients["pooled", "Std. Error"] * pooled_pred[2] +
abs(ensemble$coefficients[["unpooled"]]) * unpooled_pred[2] +
summary(ensemble)$coefficients["unpooled", "Std. Error"] * unpooled_pred[1] +
summary(ensemble)$coefficients["unpooled", "Std. Error"] * unpooled_pred[2]
final_se
abs(ensemble$coefficients[["pooled"]]) * pooled_pred[2] +
summary(ensemble)$coefficients["pooled", "Std. Error"] * pooled_pred[1] +
summary(ensemble)$coefficients["pooled", "Std. Error"] * pooled_pred[2] +
0
abs(ensemble$coefficients[["pooled"]]) * pooled_pred[2]
summary(ensemble)$coefficients["pooled", "Std. Error"] * pooled_pred[1]
pooled_pred[1]
summary(ensemnle)
summary(ensemble)
unpooled_pred = unpooled_prediction(all_state_mods, today1)
pooled_pred = pooled_prediction(districts_mod, today2)
final_prediction = ensemble$coefficients[["(Intercept)"]] +
ensemble$coefficients[["pooled"]] * pooled_pred[1] +
ensemble$coefficients[["unpooled"]] * unpooled_pred[1]
final_se = abs(ensemble$coefficients[["pooled"]]) * pooled_pred[2] +
abs(ensemble$coefficients[["unpooled"]]) * unpooled_pred[2]
final_prediction
final_se
abs(ensemble$coefficients[["pooled"]]) * pooled_pred[2]
abs(ensemble$coefficients[["unpooled"]]) * unpooled_pred[2]
unpooled_pred = unpooled_prediction(all_state_mods, today1)
pooled_pred = pooled_prediction(districts_mod, today2)
df_final = data.frame(pooled = c(pooled_pred[1],
pooled_pred[1] - 2 * pooled_pred[2],
pooled_pred[1] - 2 * pooled_pred[2],
pooled_pred[1] + 2 * pooled_pred[2],
pooled_pred[1] + 2 * pooled_pred[2]),
unpooled = c(unpooled_pred[1],
unpooled_pred[1] - 2 * unpooled_pred[2],
unpooled_pred[1] + 2 * unpooled_pred[2],
unpooled_pred[1] - 2 * unpooled_pred[2],
unpooled_pred[1] + 2 * unpooled_pred[2]))
df_final
unpooled_pred = unpooled_prediction(all_state_mods, today1)
pooled_pred = pooled_prediction(districts_mod, today2)
df_final = data.frame(pooled = c(pooled_pred[1],
pooled_pred[1] - 2 * pooled_pred[2],
pooled_pred[1] - 2 * pooled_pred[2],
pooled_pred[1] + 2 * pooled_pred[2],
pooled_pred[1] + 2 * pooled_pred[2]),
unpooled = c(unpooled_pred[1],
unpooled_pred[1] - 2 * unpooled_pred[2],
unpooled_pred[1] + 2 * unpooled_pred[2],
unpooled_pred[1] - 2 * unpooled_pred[2],
unpooled_pred[1] + 2 * unpooled_pred[2]))
df_final$predicted = predict(ensemble, df_final)
df_final
unpooled_pred = unpooled_prediction(all_state_mods, today1)
pooled_pred = pooled_prediction(districts_mod, today2)
df_final = data.frame(pooled = c(pooled_pred[1],
pooled_pred[1] - 2 * pooled_pred[2],
pooled_pred[1] - 2 * pooled_pred[2],
pooled_pred[1] + 2 * pooled_pred[2],
pooled_pred[1] + 2 * pooled_pred[2]),
unpooled = c(unpooled_pred[1],
unpooled_pred[1] - 2 * unpooled_pred[2],
unpooled_pred[1] + 2 * unpooled_pred[2],
unpooled_pred[1] - 2 * unpooled_pred[2],
unpooled_pred[1] + 2 * unpooled_pred[2]))
df_final$predicted = predict(ensemble, df_final)
min(df_final$predicted)
max(df_final$predicted)
median(df_final$predicted)
predict(ensemble, df_final, interval="confidence")
predict(ensemble, df_final, interval="prediction")
df_final
unpooled_pred = unpooled_prediction(all_state_mods, today1)
pooled_pred = pooled_prediction(districts_mod, today2)
df_final = data.frame(pooled = c(pooled_pred[1],
pooled_pred[1] - 2 * pooled_pred[2],
pooled_pred[1] + 2 * pooled_pred[2]),
unpooled = c(unpooled_pred[1],
unpooled_pred[1] + 2 * unpooled_pred[2],
unpooled_pred[1] - 2 * unpooled_pred[2]))
df_final$predicted = predict(ensemble, df_final)
df_final
errors = c()
for (yr in c(2012, 2014, 2016, 2018, 2020)) {
# Create a train/test split
df1_train = filter(df1, year != yr)
df1_test = filter(df1, year == yr)
df2_train = filter(df2, year != yr)
df2_test = filter(df2, year == yr)
# Get the models
unpooled_mods = train_unpooled_models(df1_train)
pooled_mod = train_pooled_model(df2_train)
mod = final_prediction(df1_train, df2_train)
df = data.frame(actual = filter(actuals, year == yr)$ActualPct,
pooled = pooled_prediction(pooled_mod, df2_test)[1],
unpooled = unpooled_prediction(unpooled_mods, df1_test)[1])
df$predicted = predict(mod, df)
errors = c(errors, df$predicted - df$actual)
}
# A function that gets the unpooled prediction and standard error for a dataframe, assumed to only contain one year
unpooled_prediction = function(mods, df) {
df_use = df %>%
select(state, Interaction, UnempQ4, DemPolls, DemPctPrev, MidtermFlag) %>%
right_join(pops, "state")
df_use$Pred = NA
df_use$SE = NA
for (i in 1:nrow(df_use)) {
row = df_use[i, ]
pred = predict(mods[[row$state]], row, se.fit=TRUE, type="response")
df_use[i, "Pred"] = pred$fit
df_use[i, "SE"] = pred$se.fit
}
unused_states = 1 - sum(filter(df_use, is.na(Pred))$prop)
return(c(
sum(df_use$Pred * df_use$prop / unused_states, na.rm=TRUE),
sum(df_use$SE * df_use$prop / unused_states, na.rm=TRUE)
))
}
# A function that gets the pooled prediction and standard error for a dataframe, assumed to only contain one year
pooled_prediction = function(mod, df) {
df_use = df %>%
select(Experts, `20_29`, female, black_or_latino, nominate_dim1, Incumbent, MidtermFlag)
df_use$Pred = NA
df_use$SE = NA
for (i in 1:nrow(df_use)) {
row = df_use[i, ]
pred = predict(mod, row, se.fit=TRUE, type="response")
df_use[i, "Pred"] = pred$fit
df_use[i, "SE"] = pred$se.fit
}
num_districts = sum(!is.na(df_use$Pred))
return(c(
sum(df_use$Pred / num_districts, na.rm=TRUE),
sum(df_use$SE / num_districts, na.rm=TRUE)
))
}
# A function that fits the alphas, returning a final prediction model
final_prediction = function(df1, df2) {
# Get the models
unpooled_mods = train_unpooled_models(df1)
pooled_mod = train_pooled_model(df2)
# Get the individual predictions for each year
actuals = c()
pooled_preds = c()
unpooled_preds = c()
i = 1
for (yr in unique(df2$year)) {
actuals[i] = filter(actual, year==yr)$ActualPct
pooled_preds[i] = pooled_prediction(pooled_mod, filter(df2, year==yr))[1]
unpooled_preds[i] = unpooled_prediction(unpooled_mods, filter(df1, year==yr))[1]
i = i + 1
}
df = data.frame(actual = actuals, pooled = pooled_preds, unpooled = unpooled_preds)
ensemble = lm(actual ~ pooled + unpooled, data=df)
return(ensemble)
}
ensemble = final_prediction(df1, df2)
errors = c()
for (yr in c(2012, 2014, 2016, 2018, 2020)) {
# Create a train/test split
df1_train = filter(df1, year != yr)
df1_test = filter(df1, year == yr)
df2_train = filter(df2, year != yr)
df2_test = filter(df2, year == yr)
# Get the models
unpooled_mods = train_unpooled_models(df1_train)
pooled_mod = train_pooled_model(df2_train)
mod = final_prediction(df1_train, df2_train)
df = data.frame(actual = filter(actuals, year == yr)$ActualPct,
pooled = pooled_prediction(pooled_mod, df2_test)[1],
unpooled = unpooled_prediction(unpooled_mods, df1_test)[1])
df$predicted = predict(mod, df)
errors = c(errors, df$predicted - df$actual)
}
errors = c()
for (yr in c(2012, 2014, 2016, 2018, 2020)) {
# Create a train/test split
df1_train = filter(df1, year != yr)
df1_test = filter(df1, year == yr)
df2_train = filter(df2, year != yr)
df2_test = filter(df2, year == yr)
# Get the models
unpooled_mods = train_unpooled_models(df1_train)
pooled_mod = train_pooled_model(df2_train)
mod = final_prediction(df1_train, df2_train)
df = data.frame(actual = filter(actual, year == yr)$ActualPct,
pooled = pooled_prediction(pooled_mod, df2_test)[1],
unpooled = unpooled_prediction(unpooled_mods, df1_test)[1])
df$predicted = predict(mod, df)
errors = c(errors, df$predicted - df$actual)
}
errors
df
mean(abs(errors))
sqrt(sum(errors ** 2))
sum(errors ** 2)
errors = c()
for (yr in c(2012, 2014, 2016, 2018, 2020)) {
# Create a train/test split
df1_train = filter(df1, year != yr)
df1_test = filter(df1, year == yr)
df2_train = filter(df2, year != yr)
df2_test = filter(df2, year == yr)
# Get the models
unpooled_mods = train_unpooled_models(df1_train)
pooled_mod = train_pooled_model(df2_train)
#mod = final_prediction(df1_train, df2_train)
df = data.frame(actual = filter(actual, year == yr)$ActualPct,
pooled = pooled_prediction(pooled_mod, df2_test)[1],
unpooled = unpooled_prediction(unpooled_mods, df1_test)[1])
df$predicted = predict(ensemble, df)
errors = c(errors, df$predicted - df$actual)
}
errors
mean(abs(error))
mean(abs(errors))
sum(errors ** 2)
sqrt(0.0005025017)
